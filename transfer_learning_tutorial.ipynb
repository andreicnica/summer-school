{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Code adapted from https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Transfer Learning tutorial\n",
    "==========================\n",
    "**Author**: `Sasank Chilamkurthy <https://chsasank.github.io>`_\n",
    "\n",
    "In this tutorial, you will learn how to train your network using\n",
    "transfer learning. You can read more about the transfer learning at `cs231n\n",
    "notes <http://cs231n.github.io/transfer-learning/>`__\n",
    "\n",
    "Quoting these notes,\n",
    "\n",
    "    In practice, very few people train an entire Convolutional Network\n",
    "    from scratch (with random initialization), because it is relatively\n",
    "    rare to have a dataset of sufficient size. Instead, it is common to\n",
    "    pretrain a ConvNet on a very large dataset (e.g. ImageNet, which\n",
    "    contains 1.2 million images with 1000 categories), and then use the\n",
    "    ConvNet either as an initialization or a fixed feature extractor for\n",
    "    the task of interest.\n",
    "\n",
    "These two major transfer learning scenarios look as follows:\n",
    "\n",
    "-  **Finetuning the convnet**: Instead of random initializaion, we\n",
    "   initialize the network with a pretrained network, like the one that is\n",
    "   trained on imagenet 1000 dataset. Rest of the training looks as\n",
    "   usual.\n",
    "-  **ConvNet as fixed feature extractor**: Here, we will freeze the weights\n",
    "   for all of the network except that of the final fully connected\n",
    "   layer. This last fully connected layer is replaced with a new one\n",
    "   with random weights and only this layer is trained.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "We will use torchvision and torch.utils.data packages for loading the\n",
    "data.\n",
    "\n",
    "The problem we're going to solve today is to train a model to classify\n",
    "**ants** and **bees**. We have about 120 training images each for ants and bees.\n",
    "There are 75 validation images for each class. Usually, this is a very\n",
    "small dataset to generalize upon, if trained from scratch. Since we\n",
    "are using transfer learning, we should be able to generalize reasonably\n",
    "well.\n",
    "\n",
    "This dataset is a very small subset of imagenet.\n",
    "\n",
    ".. Note ::\n",
    "   Download the data from\n",
    "   `here <https://download.pytorch.org/tutorial/hymenoptera_data.zip>`_\n",
    "   and extract it to the current directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TODO\n",
    "from models import get_model\n",
    "\n",
    "experiments_path = \"experiments/\"\n",
    "data_dir = 'datasets/'\n",
    "\n",
    "\n",
    "def save_model(model, acc, data_transforms, folder, file_name, other_info=dict()):\n",
    "    save_data = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"data_transforms\": data_transforms,\n",
    "        \"acc\": acc,\n",
    "        \"model_name\": model_name,\n",
    "    }\n",
    "    save_data.update(other_info)\n",
    "    \n",
    "    torch.save(save_data, os.path.join(folder, f\"checkpoint_{file_name}\"))\n",
    "\n",
    "\n",
    "def new_save_folder(exp_name):\n",
    "    save_f = os.path.join(experiments_path, f\"{int(time.time())}_{exp_name}\")\n",
    "    os.mkdir(save_f)\n",
    "    return save_f\n",
    "\n",
    "    \n",
    "model_name = \"alexnet\"\n",
    "\n",
    "in_size = torch.Size([3, 224, 224])\n",
    "out_size = None  # Calculate after loading data\n",
    "best_eval_acc = 0\n",
    "\n",
    "# Create experiment folder\n",
    "save_best = True\n",
    "save_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "out_size = torch.Size([len(class_names)])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few images\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's visualize a few training images so as to understand the data\n",
    "augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "from util import report_net_param\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "def plot_multi(fig_data, info):\n",
    "    if fig_data is None:\n",
    "        fig = plt.figure()\n",
    "        no_plots = len(info)\n",
    "        ax = fig.subplots((no_plots - 1) // 2 + 1, 2)\n",
    "    else:\n",
    "        fig, ax = fig_data\n",
    "\n",
    "    for ix, (plot_name, traces) in enumerate(info.items()):\n",
    "        c_ax = ax[ix//2, ix%2]\n",
    "        c_ax.clear()\n",
    "        c_ax.title.set_text(plot_name)\n",
    "        for trace_name, (x, y) in traces.items():\n",
    "            c_ax.plot(x, y, label=trace_name)\n",
    "        c_ax.legend(loc=3)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    return (fig, ax)\n",
    "\n",
    "def append_to_info(data, step, value):\n",
    "    data[0].append(step)\n",
    "    data[1].append(value)\n",
    "\n",
    "fig_data = None\n",
    "do_plot = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-  Scheduling the learning rate\n",
    "-  Saving the best model\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "``torch.optim.lr_scheduler``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, save_folder, other_info, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    all_batch_cnt = 0\n",
    "    \n",
    "    if do_plot:\n",
    "        fig_data = None\n",
    "        info = {\n",
    "            \"acc\": {\"train\": (list(), list()), \"val\": (list(), list())},\n",
    "            \"loss\": {\"train\": (list(), list()), \"val\": (list(), list())},\n",
    "            \"param\": {\"max\": (list(), list()), \"avg\": (list(), list())},\n",
    "            \"grad\": {\"max\": (list(), list()), \"avg\": (list(), list())},\n",
    "            \"output\": {\"min\": (list(), list()), \"max\": (list(), list()), \"entropy\": (list(), list())},\n",
    "        }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                        # statistics to plot\n",
    "                        if do_plot:\n",
    "                            pred_max = outputs.max().item()\n",
    "                            pred_min = outputs.min().item()\n",
    "                            norm = torch.nn.Softmax(1)(outputs.detach())\n",
    "                            pred_entropy = torch.sum(- norm * norm.log(), dim=1).mean().item()\n",
    "                            append_to_info(info[\"output\"][\"max\"], all_batch_cnt, pred_max)\n",
    "                            append_to_info(info[\"output\"][\"min\"], all_batch_cnt, pred_min)\n",
    "                            append_to_info(info[\"output\"][\"entropy\"], all_batch_cnt, pred_entropy)\n",
    "\n",
    "                            # Network info\n",
    "                            param_max, param_avg, grad_max, grad_avg = report_net_param(model)\n",
    "                            append_to_info(info[\"param\"][\"max\"], all_batch_cnt, param_max)\n",
    "                            append_to_info(info[\"param\"][\"avg\"], all_batch_cnt, param_avg)\n",
    "                            append_to_info(info[\"grad\"][\"max\"], all_batch_cnt, grad_max)\n",
    "                            append_to_info(info[\"grad\"][\"avg\"], all_batch_cnt, grad_avg)\n",
    "                        \n",
    "                        all_batch_cnt += 1\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "                if save_best:\n",
    "                    save_model(model, epoch_acc, data_transforms, save_folder, \"best\", other_info)\n",
    "\n",
    "            if save_all:\n",
    "                save_model(model, epoch_acc, data_transforms, save_folder, str(epoch), other_info)\n",
    "\n",
    "            # statistics to plot\n",
    "            if do_plot:\n",
    "                append_to_info(info[\"acc\"][phase], epoch, epoch_acc)\n",
    "                append_to_info(info[\"loss\"][phase], epoch, epoch_loss)\n",
    "\n",
    "\n",
    "        if do_plot:\n",
    "            fig_data = plot_multi(fig_data, info)\n",
    "            \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the model predictions\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Generic function to display predictions for a few images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning the convnet\n",
    "----------------------\n",
    "\n",
    "Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not loading layer: classifier.6.weight\n",
      "Not loading layer: classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "model_ft = get_model(model_name, in_size=in_size, out_size=out_size, pretrained=True)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "It should take around 15-25 min on CPU. On GPU though, it takes less than a\n",
    "minute.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.0750 Acc: 0.9720\n",
      "val Loss: 0.0000 Acc: 1.0000\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0000 Acc: 1.0000\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-24:\n",
      "Process Process-22:\n",
      "Process Process-23:\n",
      "Process Process-21:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "    return pil_loader(path)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f978f3936d8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/andrei/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 10650) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-eed76c243c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mother_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"in_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, save_folder, other_info,\n\u001b[0;32m----> 4\u001b[0;31m                        num_epochs=5)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-ed8fc4331bb0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, save_folder, other_info, num_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_folder = new_save_folder(\"summer_full_train\")\n",
    "other_info = {\"in_size\": in_size, \"out_size\": out_size, \"model_name\": model_name}\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, save_folder, other_info,\n",
    "                       num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet as fixed feature extractor\n",
    "----------------------------------\n",
    "\n",
    "Here, we need to freeze all the network except the final layer. We need\n",
    "to set ``requires_grad == False`` to freeze the parameters so that the\n",
    "gradients are not computed in ``backward()``.\n",
    "\n",
    "You can read more about this in the documentation\n",
    "`here <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not loading layer: classifier.6.weight\n",
      "Not loading layer: classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "model_conv = get_model(model_name, in_size=in_size, out_size=out_size, pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "# Custom for alexnet \n",
    "num_ftrs3 = model_conv.classifier[-3].in_features\n",
    "num_ftrs1 = model_conv.classifier[-1].in_features\n",
    "model_conv.classifier[-3] = nn.Linear(num_ftrs3, num_ftrs1)\n",
    "model_conv.classifier[-1] = nn.Linear(num_ftrs1, out_size[0])\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opoosed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.classifier[-1].parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "On CPU this will take about half the time compared to previous scenario.\n",
    "This is expected as gradients don't need to be computed for most of the\n",
    "network. However, forward does need to be computed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "tensor(1.00000e-02 *\n",
      "       1.4880, device='cuda:0')\n",
      "tensor(1.4196, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.4816, device='cuda:0')\n",
      "tensor(1.4196, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.4769, device='cuda:0')\n",
      "tensor(1.4196, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.5038, device='cuda:0')\n",
      "tensor(1.4196, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.5422, device='cuda:0')\n",
      "tensor(1.4196, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.5571, device='cuda:0')\n",
      "tensor(1.4197, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.5523, device='cuda:0')\n",
      "tensor(1.4197, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.5956, device='cuda:0')\n",
      "tensor(1.4197, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.6405, device='cuda:0')\n",
      "tensor(1.4198, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.6662, device='cuda:0')\n",
      "tensor(1.4198, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.6382, device='cuda:0')\n",
      "tensor(1.4199, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.5969, device='cuda:0')\n",
      "tensor(1.4200, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.5879, device='cuda:0')\n",
      "tensor(1.4201, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.5897, device='cuda:0')\n",
      "tensor(1.4201, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.6111, device='cuda:0')\n",
      "tensor(1.4202, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.6382, device='cuda:0')\n",
      "tensor(1.4203, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.6889, device='cuda:0')\n",
      "tensor(1.4204, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.7431, device='cuda:0')\n",
      "tensor(1.4204, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.7901, device='cuda:0')\n",
      "tensor(1.4205, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8329, device='cuda:0')\n",
      "tensor(1.4206, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8515, device='cuda:0')\n",
      "tensor(1.4207, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8610, device='cuda:0')\n",
      "tensor(1.4208, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8629, device='cuda:0')\n",
      "tensor(1.4208, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8647, device='cuda:0')\n",
      "tensor(1.4209, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8576, device='cuda:0')\n",
      "tensor(1.4210, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8476, device='cuda:0')\n",
      "tensor(1.4210, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8370, device='cuda:0')\n",
      "tensor(1.4211, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8223, device='cuda:0')\n",
      "tensor(1.4211, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8095, device='cuda:0')\n",
      "tensor(1.4212, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.7957, device='cuda:0')\n",
      "tensor(1.4212, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.7927, device='cuda:0')\n",
      "tensor(1.4213, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.7918, device='cuda:0')\n",
      "tensor(1.4213, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.7903, device='cuda:0')\n",
      "tensor(1.4214, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.7888, device='cuda:0')\n",
      "tensor(1.4214, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.7921, device='cuda:0')\n",
      "tensor(1.4214, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.7950, device='cuda:0')\n",
      "tensor(1.4215, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8018, device='cuda:0')\n",
      "tensor(1.4215, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8083, device='cuda:0')\n",
      "tensor(1.4215, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8273, device='cuda:0')\n",
      "tensor(1.4215, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8446, device='cuda:0')\n",
      "tensor(1.4216, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8601, device='cuda:0')\n",
      "tensor(1.4216, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8732, device='cuda:0')\n",
      "tensor(1.4216, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8792, device='cuda:0')\n",
      "tensor(1.4216, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8845, device='cuda:0')\n",
      "tensor(1.4216, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8894, device='cuda:0')\n",
      "tensor(1.4217, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8926, device='cuda:0')\n",
      "tensor(1.4217, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8923, device='cuda:0')\n",
      "tensor(1.4217, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8941, device='cuda:0')\n",
      "tensor(1.4217, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8959, device='cuda:0')\n",
      "tensor(1.4217, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8959, device='cuda:0')\n",
      "tensor(1.4217, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8954, device='cuda:0')\n",
      "tensor(1.4217, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8948, device='cuda:0')\n",
      "tensor(1.4217, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8895, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8847, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8799, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8762, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8733, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8711, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8701, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8692, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8708, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8723, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8746, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8768, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8787, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8811, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8832, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8851, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8870, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8919, device='cuda:0')\n",
      "tensor(1.4218, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8964, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9005, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9040, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9072, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9101, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9130, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9152, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9164, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9168, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9172, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9172, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9180, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9185, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9189, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9196, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9206, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9200, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9194, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9192, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9190, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9213, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9234, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9247, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9264, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9268, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9271, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9273, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-02 *\n",
      "       1.9272, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9271, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9258, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9249, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9229, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9203, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9164, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9134, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9108, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9098, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9093, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9084, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9077, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9071, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9058, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9087, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9105, device='cuda:0')\n",
      "tensor(1.4219, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9037, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8978, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8929, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8888, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8850, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8830, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8810, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8817, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8825, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8877, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8975, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9065, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9153, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9252, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9341, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9417, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9489, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9554, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9605, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9619, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9630, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9612, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9476, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9366, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9268, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9180, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9105, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9037, device='cuda:0')\n",
      "tensor(1.4220, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8980, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "train Loss: 0.0761 Acc: 0.9615\n",
      "val Loss: 0.0061 Acc: 1.0000\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "tensor(1.00000e-02 *\n",
      "       1.8927, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8885, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8848, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8821, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8805, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8810, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8821, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8868, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8910, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8944, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8978, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9006, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9089, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9165, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9186, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9206, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9224, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9239, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9248, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9255, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9265, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9275, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9283, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9273, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9271, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9275, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9277, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9279, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9281, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9284, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9285, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9292, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9251, device='cuda:0')\n",
      "tensor(1.4221, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9215, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9182, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9153, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9128, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9311, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9475, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9622, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9722, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9812, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9893, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9968, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       2.0035, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       2.0057, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       2.0077, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       2.0093, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       2.0091, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       2.0089, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       2.0085, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-02 *\n",
      "       2.0082, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       2.0059, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       2.0026, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9991, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9953, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9915, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9880, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9771, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9673, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9568, device='cuda:0')\n",
      "tensor(1.4222, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9471, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9385, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9334, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9280, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9229, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9184, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9121, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9065, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8998, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8938, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8883, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8879, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8887, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8896, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8904, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9037, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9159, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9268, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9362, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9386, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9408, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9437, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9464, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9379, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9303, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9235, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9174, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9118, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9068, device='cuda:0')\n",
      "tensor(1.4223, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9036, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9006, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.8993, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9034, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9070, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9121, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9166, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9205, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9239, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9256, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9273, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9316, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9356, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9391, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9422, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9444, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9463, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9481, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9496, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9511, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9523, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9537, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9550, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9562, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9573, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9584, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9594, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9621, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9642, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9652, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9643, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9649, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9655, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9662, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9665, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9668, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9663, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9659, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9668, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9676, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9684, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9688, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9691, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9693, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9672, device='cuda:0')\n",
      "tensor(1.4224, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9650, device='cuda:0')\n",
      "tensor(1.4225, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9631, device='cuda:0')\n",
      "tensor(1.4225, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9614, device='cuda:0')\n",
      "tensor(1.4225, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9598, device='cuda:0')\n",
      "tensor(1.4225, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9575, device='cuda:0')\n",
      "tensor(1.4225, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9553, device='cuda:0')\n",
      "tensor(1.4225, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9535, device='cuda:0')\n",
      "tensor(1.4225, device='cuda:0')\n",
      "tensor(1.00000e-02 *\n",
      "       1.9514, device='cuda:0')\n",
      "tensor(1.4225, device='cuda:0')\n",
      "train Loss: 0.0138 Acc: 0.9982\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8e3e7be05e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mother_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"in_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model_conv = train_model(model_conv, criterion, optimizer_conv, \n\u001b[0;32m----> 4\u001b[0;31m                          exp_lr_scheduler, save_folder, other_info, num_epochs=25)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-1edaef47caa9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, save_folder, other_info, num_epochs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdo_plot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ac2b90e54d01>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, acc, data_transforms, folder, file_name, other_info)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msave_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"checkpoint_{file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/old_pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mserialized_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_real_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_folder = new_save_folder(\"summer_fine_tune\")\n",
    "other_info = {\"in_size\": in_size, \"out_size\": out_size, \"model_name\": model_name}\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv, \n",
    "                         exp_lr_scheduler, save_folder, other_info, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_conv)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
